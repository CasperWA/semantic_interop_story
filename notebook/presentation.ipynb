{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dfa9308-5b60-47c7-bc16-84fee5c00d85",
   "metadata": {},
   "source": [
    "# Semantic Interoperability\n",
    "\n",
    "This is a story about Bob and Alice. Bob is working hard to generate data. He collects information from sensor systems and publish the data. Alice is an analytician and consumes data for running her forecasting and business support systems. Alice collects information from different systems, but the data is organized and structured differently for each provider. However, she knows how the input of her analysis tools should be structured. \n",
    "\n",
    "Bob is producing data for a lot of consumers, all using different systems and software. To ensure his knowledge about what data is provided, how the data was aquired, which analysis methods were used, what unit-system and representations has been encoded etc he documents all this information in a machine readable way. \n",
    "\n",
    "Alice does not have time or the knowledge to adopt Bobs data to her analytics tool, but she realizes that since machines are able to interpret Bobs data she can document her requirements in a similar fashion, and then let the computers figure out how to brigde the two representations. Alice discovers that such systems actually exists, and learns that they are called \"frameworks for semantic interoperability\". Eager to learn how this actually works, she asks Bob to give her a documented dataset.\n",
    "\n",
    "Bob is busy, but explains that there exist a set of example CSV-files on the internet she can play with, and insist the CSV files contains enough information in them for her to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2024ee-d84c-41c9-80a4-50ffa46da3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://cds.climate.copernicus.eu/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dc690f-3867-48ad-af81-b1b86be355ce",
   "metadata": {},
   "source": [
    "This dataset provides bias-corrected reconstruction of near-surface meteorological variables derived from the fifth generation of the European Centre for Medium-Range Weather Forecasts (ECMWF) atmospheric reanalyses (ERA5). It is intended to be used as a meteorological forcing dataset for land surface and hydrological models.\n",
    "\n",
    "The dataset has been obtained using the same methodology used to derive the widely used water, energy and climate change (WATCH) forcing data, and is thus also referred to as WATCH Forcing Data methodology applied to ERA5 (WFDE5). The data are derived from the ERA5 reanalysis product that have been re-gridded to a half-degree resolution. Data have been adjusted using an elevation correction and monthly-scale bias corrections based on Climatic Research Unit (CRU) data (for temperature, diurnal temperature range, cloud-cover, wet days number and precipitation fields) and Global Precipitation Climatology Centre (GPCC) data (for precipitation fields only). Additional corrections are included for varying atmospheric aerosol-loading and separate precipitation gauge observations. For full details please refer to the product user-guide.\n",
    "\n",
    "This dataset was produced on behalf of Copernicus Climate Change Service (C3S) and was generated entirely within the Climate Data Store (CDS) Toolbox. The toolbox source code is provided in the documentation tab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21dbb3d1-b159-4b41-8cec-9589beb743c4",
   "metadata": {},
   "source": [
    "Name | Units | Description\n",
    "---|---|---\n",
    "Grid-point altitude\t | m | The altitude of each grid-point. Values correspond to altitudes of CRU grid-points.\n",
    "Near-surface air temperature | K | The temperature of air at 2 metres above the surface of land, sea or inland waters. Values are derived from ERA5 2m air temperature with an elevation correction and bias correction using CRU mean monthly temperature and mean diurnal temperature range.\n",
    "Near-surface specific humidity | kg kg-1 | The amount of moisture in the air divided by amount of air plus moisture at that location. Values are derived from ERA5 vapor pressure and saturation vapor pressure with an elevation correction.\n",
    "Near-surface wind speed | m s-1 | The horizontal speed of the wind, or movement of air, at a height of 10 metres above the surface of the Earth. Values are derived from ERA5 near-surface wind speed.\n",
    "Rainfall flux | kg m-2 s-1 | The rate of rain that falls to the Earth's surface. Values are derived from ERA5 total precipitation and snowfall and are bias corrected primarily using precipitation data from CRU and GPCC.\n",
    "Snowfall flux | kg m-2 s-1 | The rate of snow that falls to the Earth's surface. Values are derived from ERA5 total precipitation and snowfall and are bias corrected primarily using precipitation data from CRU and GPCC.\n",
    "Surface air pressure | Pa | The pressure (force per unit area) of the atmosphere at the surface of land, sea and inland water. Values are derived from ERA5 surface air pressure with an elevation correction.\n",
    "Surface downwelling longwave radiation | W m-2 | The amount of thermal (also known as longwave or terrestrial) radiation emitted by the atmosphere and clouds that reaches a horizontal plane at the surface of the Earth. Values are derived from ERA5 surface downwelling longwave radiation with an elevation correction.\n",
    "Surface downwelling shortwave radiation | W m-2 | The amount of solar radiation (also known as shortwave radiation) that reaches a horizontal plane at the surface of the Earth. This parameter comprises both direct and diffuse solar radiation. Values are derived from ERA5 surface downwelling shortwave radiation and bias corrected using CRU cloud cover and effects of inter-annual changes in atmospheric aerosol loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25a4220-ef60-4a85-ae52-942ed22cf9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "\n",
    "class Snowfall(BaseModel):\n",
    "    lat  : List[float]\n",
    "    lon  : List[float]\n",
    "    time : List[float]\n",
    "    Snowf : \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a06dfdc-0e03-4702-87c8-f1dfe17245a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Dataset'>\n",
      "root group (NETCDF4 data model, file format HDF5):\n",
      "    title: WATCH Forcing Data methodology applied to ERA5 data\n",
      "    institution: Copernicus Climate Change Service\n",
      "    contact: http://copernicus-support.ecmwf.int\n",
      "    comment: Methodology implementation for ERA5 and dataset production by B-Open Solutions for the Copernicus Climate Change Service in the context of contract C3S_25c\n",
      "    Conventions: CF-1.7\n",
      "    summary: ERA5 data regridded to half degree regular lat-lon; Genuine land points from CRU grid and ERA5 land-sea mask only; Snowf bias-corrected using CRU TS4.04 wet days & GPCCv2020 precip totals, catch correction, and precip phase correction according to elevation and bias-corrected Tair\n",
      "    reference: Cucchi et al., 2020, Earth Syst. Sci. Data, 12(3), 2097â€“2120, doi:10.5194/essd-12-2097-2020; Weedon et al., 2014, Water Resources Res., 50, 7505-7514, doi:10.1002/2014WR015638; Harris et al., 2020, Scientific Data, 7(1), doi:10.1038/s41597-020-0453-3; Schneider, U., Becker, A., Finger, P., Meyer-Christoffer, A., Ziese, M., 2018 GPCC Full Data Product version 2018 at 0.5o: Monthly land-surface precipitation from rain-gauges built on GTS-based and historical data, doi:10.5676/DWD_GPCC/FD_M_V2018_050; Schneider et al. 2017 Atmosphere 8, 52 doi:10.3390/atmos8030052; Schneider et al. 2013 Theor. Appl. Climatol.115, 15-40, doi:10.1007/s00704-013-08600-x\n",
      "    licence: The dataset is distributed under the Licence to Use Copernicus Products. The corrections applied are based upon CRU TS4.04, distributed under the Open Government Licence (OGL), and GPCCv2020, distributed under the Creative Commons Attribution 4.0 International Licence (CC BY 4.0)\n",
      "    dimensions(sizes): lat(360), lon(720), time(744)\n",
      "    variables(dimensions): float64 lat(lat), float64 lon(lon), int64 time(time), float32 Snowf(time, lat, lon)\n",
      "    groups: \n"
     ]
    }
   ],
   "source": [
    "import netCDF4\n",
    "import numpy as np\n",
    "f = netCDF4.Dataset('datasets/Snowf_WFDE5_CRU+GPCC_201901_v2.0.nc')\n",
    "print (f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8df2303-9d4f-405d-bfa1-aeec9af75a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lat <class 'netCDF4._netCDF4.Variable'>\n",
      "float64 lat(lat)\n",
      "    _FillValue: nan\n",
      "    long_name: Latitude\n",
      "    units: degrees_north\n",
      "    standard_name: latitude\n",
      "    axis: Y\n",
      "unlimited dimensions: \n",
      "current shape = (360,)\n",
      "filling on \n",
      "\n",
      "lon <class 'netCDF4._netCDF4.Variable'>\n",
      "float64 lon(lon)\n",
      "    _FillValue: nan\n",
      "    long_name: Longitude\n",
      "    units: degrees_east\n",
      "    standard_name: longitude\n",
      "    axis: X\n",
      "    type: double\n",
      "    valid_max: 360.0\n",
      "    valid_min: -180.0\n",
      "unlimited dimensions: \n",
      "current shape = (720,)\n",
      "filling on \n",
      "\n",
      "time <class 'netCDF4._netCDF4.Variable'>\n",
      "int64 time(time)\n",
      "    standard_name: time\n",
      "    long_name: Time\n",
      "    axis: T\n",
      "    units: hours since 1900-01-01\n",
      "    calendar: proleptic_gregorian\n",
      "unlimited dimensions: \n",
      "current shape = (744,)\n",
      "filling on, default _FillValue of -9223372036854775806 used \n",
      "\n",
      "Snowf <class 'netCDF4._netCDF4.Variable'>\n",
      "float32 Snowf(time, lat, lon)\n",
      "    _FillValue: 1e+20\n",
      "    units: kg m-2 s-1\n",
      "    long_name: Snowfall Flux\n",
      "    standard_name: snowfall_flux\n",
      "unlimited dimensions: \n",
      "current shape = (744, 360, 720)\n",
      "filling on \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key in (f.variables.keys()):    \n",
    "    variable = f.variables[key]\n",
    "    print (key, variable, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9b2f435-d1bd-4c36-a3aa-68c97f68b7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('lat', <class 'netCDF4._netCDF4.Dimension'>: name = 'lat', size = 360)\n",
      "('lon', <class 'netCDF4._netCDF4.Dimension'>: name = 'lon', size = 720)\n",
      "('time', <class 'netCDF4._netCDF4.Dimension'>: name = 'time', size = 744)\n"
     ]
    }
   ],
   "source": [
    "for dim in f.dimensions.items():\n",
    "    print(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1c91235-042c-4d5d-8f92-f01615ac3dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "masked_array(\n",
       "  data=[[[0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "         [0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "         [0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "         ...,\n",
       "         [--, --, --, ..., --, --, --],\n",
       "         [--, --, --, ..., --, --, --],\n",
       "         [--, --, --, ..., --, --, --]],\n",
       "\n",
       "        [[0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "         [0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "         [0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "         ...,\n",
       "         [--, --, --, ..., --, --, --],\n",
       "         [--, --, --, ..., --, --, --],\n",
       "         [--, --, --, ..., --, --, --]],\n",
       "\n",
       "        [[0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "         [0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "         [0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "         ...,\n",
       "         [--, --, --, ..., --, --, --],\n",
       "         [--, --, --, ..., --, --, --],\n",
       "         [--, --, --, ..., --, --, --]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "         [0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "         [0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "         ...,\n",
       "         [--, --, --, ..., --, --, --],\n",
       "         [--, --, --, ..., --, --, --],\n",
       "         [--, --, --, ..., --, --, --]],\n",
       "\n",
       "        [[0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "         [0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "         [0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "         ...,\n",
       "         [--, --, --, ..., --, --, --],\n",
       "         [--, --, --, ..., --, --, --],\n",
       "         [--, --, --, ..., --, --, --]],\n",
       "\n",
       "        [[0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "         [0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "         [0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "         ...,\n",
       "         [--, --, --, ..., --, --, --],\n",
       "         [--, --, --, ..., --, --, --],\n",
       "         [--, --, --, ..., --, --, --]]],\n",
       "  mask=[[[False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         ...,\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "        [[False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         ...,\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "        [[False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         ...,\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         ...,\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "        [[False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         ...,\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "        [[False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         ...,\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True]]],\n",
       "  fill_value=1e+20,\n",
       "  dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snow = f.variables['Snowf']\n",
    "snow[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2705183-d764-4d1e-8772-42458f40866b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
